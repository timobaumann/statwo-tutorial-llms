{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c22671-354d-4e6a-905c-d521215dfd5a",
   "metadata": {},
   "source": [
    "# This notebook contains an implementation for NN-based language modelling. \n",
    "At the core, a language model is a sequence classifier that uses all the tokens produced so far as input in order to produce a probability density function over all possible next tokens (a token could be a word, a character, or something inbetween). We can then either use the \"best possible guess\" of the classifier as the next token, or we can sample from the distribution according to the distribution. \n",
    "\n",
    "In fact, producing a probability density function comes for free, when we build a neural classifier that uses a softmax output activation. Therefore, nothing actually changes from \"before\", when we simply built classifiers.\n",
    "\n",
    "Once we have trained the model, we repeatedly ask for next tokens, and add these to the context. This is called \"autoregressive sequence generation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68ece420-fb26-40ba-9037-0fb3aec77875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3b6b4b7-6a64-467a-a626-ce5b637d5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '</s>', '<s>', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}'] 86\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "\n",
    "source = \"data/shakespeare-en.txt\" # other files in data: lyrik-de.txt, dialoge-de.txt, merkel-de.txt\n",
    "N = 4\n",
    "\n",
    "\n",
    "START_SYMBOL = \"<s>\"\n",
    "END_SYMBOL = \"</s>\"\n",
    "data = open(source, 'r').read() # should be simple plain text file\n",
    "characters = set(data)\n",
    "characters.add(START_SYMBOL)\n",
    "characters.add(END_SYMBOL)\n",
    "characters = list(sorted(characters))\n",
    "NUM_CHARACTERS = len(characters)\n",
    "int2char = list(characters)\n",
    "char2int = {c:i for i,c in enumerate(characters)}\n",
    "print(characters, len(characters))\n",
    "NUM_CLASSES = NUM_CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a5905f6-4924-40fb-b8be-be39b34f995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_ids_from_text(f, N):\n",
    "    '''\n",
    "    Given a text file (f), create all pairs of (context,next) in that file.\n",
    "    This code is ignorant of line starts and endings and considers all the data as one string.\n",
    "    NOTE: as compared to the previous version, this outputs characterIDs, rather than actual characters\n",
    "    '''\n",
    "    for line in open(f, 'r').readlines():\n",
    "        context = [START_SYMBOL] * (N - 1)\n",
    "        symbols = list(line.rstrip()) + [END_SYMBOL]\n",
    "        for last in symbols:\n",
    "            yield ([char2int[c] for c in context], char2int[last])\n",
    "            context.append(last) # append last element\n",
    "            context.pop(0) # get rid of first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d371db5a-6d2d-4be5-bd0b-cd74e277a1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([25, 25, 25], 24)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams_ids_from_text(source, N))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7caf0d39-931f-496b-9006-2685ccdb524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = NUM_CHARACTERS * (N-1)\n",
    "NUM_CLASSES = NUM_CHARACTERS\n",
    "MAX_GENERATION_LENGTH = 800\n",
    "\n",
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LM, self).__init__()\n",
    "        self.final_layer = nn.Linear(INPUT_SIZE, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, xs: torch.Tensor) -> torch.Tensor:\n",
    "        xs = torch.nn.functional.one_hot(torch.LongTensor(xs), num_classes=NUM_CLASSES)\n",
    "        xs = xs.reshape((INPUT_SIZE,)).float()\n",
    "        return self.final_layer(xs)\n",
    "\n",
    "    def generate(self, xs=torch.tensor([char2int[START_SYMBOL]] * (N-1)), sample=\"max\") -> torch.tensor:\n",
    "        \"\"\"sample can be \"max\" or \"prop\" for max likelihood or proportional sampling\"\"\"\n",
    "        classification = None\n",
    "        output = []\n",
    "        while ((classification == None) or (classification.item() != char2int[END_SYMBOL])) and (len(output) < MAX_GENERATION_LENGTH):\n",
    "            if sample == \"max\":\n",
    "                classification = torch.argmax(self.forward(xs))\n",
    "            elif sample == \"prop\":\n",
    "                classification = torch.multinonomial(self.forward(xs), 1)[0]\n",
    "            else:\n",
    "                assert False, \"only max and prop are possible values for sample!\"\n",
    "            print(classification)\n",
    "            output.append(classification)\n",
    "            xs = torch.concat([xs[1:], classification])\n",
    "        output = torch.stack(output[:-1]) if len(output) > 1 else torch.tensor([])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5849d62-ca5b-4513-9b12-75d5c54a767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 5\n",
    "\n",
    "lm = LM()\n",
    "optimizer = torch.optim.SGD(lm.parameters(), lr=0.01)\n",
    "\n",
    "ngrams = list(ngrams_ids_from_text(source, N))\n",
    "\n",
    "def training(ngrams):\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        print((\"Epoch {} starting\".format(epoch+1)))\n",
    "        for ngram in ngrams:\n",
    "            optimizer.zero_grad()\n",
    "            print(ngram[0])\n",
    "            output = lm(ngram[0])\n",
    "            loss = nn.functional.nll_loss(output, ngram[1])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #print(\"forced: \" + \"\".join([int2char[x] for x in torch.argmax(lm(training_data[0][:-1]), dim=1)]))\n",
    "        print(\"freemax:\" + \"\".join([int2char[x] for x in lm.generate()]))\n",
    "        print(\"fresamp:\" + \"\".join([int2char[x] for x in lm.generate(sample=\"prop\")]))\n",
    "        if epoch < MAX_EPOCHS - 1:\n",
    "            random.shuffle(ngrams)\n",
    "    return lm\n",
    "\n",
    "training(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fab8c0d-f97f-41e7-8be3-f8269abb6416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c87889a-e96a-46a2-b532-5acaeb181f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([25, 47, 35], 32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1f93e-f013-4d7a-8821-03e05c6e6ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
